#### <center>添加新算法示例</center>

#### 1、任务描述

本示例介绍了向框架中添加一个新任务（肺部分割模型及其攻击算法）的过程，添加新任务包含以下几步：

1、新的向框架中添加一个肺部图像分割的U-Net样例模型和数据

2、针对此模型，添加一个样例的对抗攻击算法

3、在使用对抗算法生成对抗测试数据集后，对新数据集的性能进行评价

注：为了评估扰动生成的数据集的质量，在使用生成数据集对模型进行性能评价前，首先需要对新数据集进行一个评价，通过特定的指标来衡量生成数据集的有效性。故框架的任务拆成了create_dataset和evaluate_only两个部分，前者用于生成数据集及评价数据集，后者用于评价模型在新数据集上的表现。添加一个新任务的改动主要与create_dataset有关。

#### 2、添加步骤

##### step1 将样例数据集以固定格式整理好，并注册分割数据集类

对于分割模型，其数据集包含了待分割图像和分割的掩模，其文件结构大致如下：

```
├── images
│   ├── MCUCXR_0001_0.png
│   ├── MCUCXR_0002_0.png
│   ├── MCUCXR_0008_0.png
│   ├── MCUCXR_0013_0.png
│   ├── MCUCXR_0015_0.png
│   ├── MCUCXR_0017_0.png
│   ├── MCUCXR_0019_0.png
│   ├── MCUCXR_0022_0.png
│   ├── MCUCXR_0044_0.png
│   └── MCUCXR_0046_0.png
└── masks
    ├── MCUCXR_0001_0.png
    ├── MCUCXR_0002_0.png
    ├── MCUCXR_0008_0.png
    ├── MCUCXR_0013_0.png
    ├── MCUCXR_0015_0.png
    ├── MCUCXR_0017_0.png
    ├── MCUCXR_0019_0.png
    ├── MCUCXR_0022_0.png
    ├── MCUCXR_0044_0.png
    └── MCUCXR_0046_0.png
```

根目录下包含了两个文件夹，分别用于存储图像和其分割的掩模。将数据集的根目录放在datasets/文件夹下，如本例中的lung_seg。

注册数据集类，在框架backend/lib/datasets/文件夹下创建新的dataset脚本，如dataset_lungseg.py，完成其\_\_init\_\_、\_\_getitem\_\_、\_\_len\_\_方法用于基本的数据处理，完善init，add两个类方法用于扰动后数据的保存，其内容如下：

```python
import pathlib
from torch._C import parse_type_comment
from torch.utils.data.dataset import Dataset
import numpy as np
import os
import cv2

import torch
from torch.utils.data import Dataset
import skimage.io
import json
from pathlib import Path
from .factory import DatasetFactory


@DatasetFactory.register('dataset_lungseg_basic')
class LungSegBasic(Dataset):
    params = {
        "root_dir":{
            "description":"模型的根路径",
            "value_type":"string",
            "value_range":"正确路径即可",
            "default":"test/lung_seg"
        },
        "resize":{
            "description":"图像缩放的边长",
            "value_type":"int",
            "value_range":"要与模型支持的输入大小一致",
            "default":864
        }
    }
    def __init__(self, root_dir = './',resize = 864):
        self.img_path = os.path.join(root_dir,'images')
        self.mask_path = os.path.join(root_dir,'masks')
        self.list = os.listdir(self.img_path)
        self.resize = resize
        
    def __getitem__(self, index):
        """Get a sample pair (image,mask) by an index"""
        image = cv2.imread(os.path.join(self.img_path, self.list[index]))
        mask = cv2.imread(os.path.join(self.mask_path, self.list[index]))
        image = cv2.resize(image, (self.resize, self.resize))
        image = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2RGB)
        mask = cv2.resize(mask, (self.resize, self.resize))
        meta = {'path': self.list[index]}
        return (image, mask, meta)

    def __len__(self):
        """Return the size of the dataset"""
        return len(self.list) 

    @classmethod
    def init(cls, init_params):
        print("Dataset Init!")
        root_dir_target = init_params['root_dir']
        root_dir_target = Path(root_dir_target)
        root_dir_target.mkdir(parents=True,exist_ok=True)
        (root_dir_target/'images').mkdir(parents=True,exist_ok=True)
        (root_dir_target/'masks').mkdir(parents=True,exist_ok=True)
        dataset_params = {
            'root_dir': str(root_dir_target),
        }
        return dataset_params

    
    @classmethod
    def add(cls, img_new, mask_new, meta_new, dataset_info):
        dataset_info = dataset_info.copy() # 可以不用
        root_dir = dataset_info['root_dir']
        root_dir = Path(root_dir)
        image_path_str = meta_new['path']
        image_output_path = root_dir/'images'/image_path_str
        image_output_path.parent.mkdir(parents=True,exist_ok=True)
        mask_output_path = root_dir/'masks'/image_path_str
        mask_output_path.parent.mkdir(parents=True,exist_ok=True)
        # 保存新图片和掩模
        if isinstance(img_new,torch.Tensor):
            img_new = img_new.to('cpu').numpy()
            mask_new = mask_new.to('cpu').numpy()
        skimage.io.imsave(fname=image_output_path,arr=img_new)
        skimage.io.imsave(fname=mask_output_path,arr=mask_new)
        # dataset_info['_count'] = count+1

        return dataset_info
```

**添加完成新的类后，需要在backend/lib/datasets/\_\_init\_\_.py中将对应的文件import进来，以完成注册。**



##### step2 注册分割模型类

需要通过torch.jit来读取一个本地模型参数，在框架models/文件夹下存放模型参数，如jit_lungseg.pth。

注册分割模型类，在框架backend/lib/models/文件夹下添加新的模型脚本，如model_lungseg.py，完成其forward、predict方法用于基本的数据处理，其内容如下：

```python
import torch
from torch._C import device
import torch.nn as nn
import requests
from torchvision.transforms import transforms
import copy

from backend.lib.models.factory import ModelFactory

@ModelFactory.register('model_lungseg_basic')
class LungSegBasic(nn.Module):
    params = {
        'model_path':{
            "description":"已训练的模型参数的路径，文件以.pth结尾",
            "value_type":"string",
            "value_range":"正确路径即可",
            "default":"models/jit_lungseg.pth"
        },
        'threshold':{
            "description":"模型输出为正例的阈值",
            'value_type':"float",
            "value_range":"0~1之间的浮点数",
            "default":0.5
        },
        'device':{
            "description":"算法运行的设备",
            "value_type":"enum",
            "value_range":["cpu","cuda"],
            "default":"cpu"
        }
    }
    def __init__(self,path,threshold=0.5, device='cpu'):
        super(LungSegBasic, self).__init__()
        self.model = torch.jit.load(path).to(device)
        self.threshold = threshold
        self.device = device
        self._to_tensor = transforms.ToTensor()

    def forward(self, x):
        '''
        x: np.array[H,W,3]
        '''
        # x = self._to_tensor(x)
        # print("Input shape:", x.shape)
        # print("Model Device:", self.device)
        if len(x.shape) == 3:
            x = x.unsqueeze(0)
        # print(self.model)
        # print(x)
        output = self.model(x)
        prob = torch.sigmoid(output)
        # pred = torch.tensor(output)
        pred = torch.zeros(output.shape)
        # pred = copy.deepcopy(output)
        pred[prob >= self.threshold] = 1
        pred[prob < self.threshold] = 0
        # print("Output shape:", pred.shape)
        
        return pred, prob

    def predict(self, x):
        if len(x.shape) == 3:
            x = x.unsqueeze(0)
        output = self.model(x)
        prob = torch.sigmoid(output)
        pred = torch.zeros(output.shape)
        # pred = copy.deepcopy(output)
        pred[prob >= self.threshold] = 1
        pred[prob < self.threshold] = 0
        return pred.cpu().detach().numpy()
```

**添加完成新的类后，需要在backend/lib/models/\_\_init\_\_.py中将对应的文件import进来，以完成注册。**



##### step3 注册攻击算法类

为了简便，示例中采用了通用扰动如高斯模糊、噪声等，在框架/backend/lib/algorithms/文件夹下存放对抗攻击算法脚本，如algorithm_lungseg.py，完成其run方法，其结果要求为一张对抗攻击后的图片、图片的标签（在此为肺部的掩模）、以及一个meta信息，包括了模型在原有图片和对抗后图片上的预测结果。

```python
import albumentations
import torchvision.transforms as transforms
import numpy as np
import random
import torch

from .factory import TestFactory


img_to_tensor = transforms.ToTensor()



#Pad an image to make it square
def pad_img(img):
    # print(len(img.shape))
    if len(img.shape) == 3:
        x,y,c = img.shape
    else:
        x,y = img.shape
        c = 3
        img = img[:,:,np.newaxis]
        img = np.repeat(img, c, axis=2)

    # print(c)
    if x > y:
        pad_len = int((x-y)/2)
        padded = np.zeros((x,x,3))
        if (x-y) % 2 == 0:
            padded[:,pad_len:x-pad_len,:] = img
        else:
            padded[:,pad_len+1:x-pad_len,:] = img
    else:
        pad_len = int((y-x)/2)
        padded = np.zeros((y,y,3))
        if (y-x) % 2 == 0:
            padded[pad_len:y-pad_len,:,:] = img
        else:
            padded[pad_len+1:y-pad_len,:,:] = img
    return padded

#Add gaussian noise to an image
def add_gaussian_noise(pic,noise_sigma=[10,50],p=0.3):
    num = np.random.rand()
    if num >= p:
        return pic
    temp_image = np.float64(np.copy(pic))
    sigma_range = np.arange(noise_sigma[0],noise_sigma[1])
    sigma = random.sample(list(sigma_range),1)[0]
    h, w, _ = temp_image.shape
    #Standard norm * noise_sigma
    noise = np.random.randn(h, w) * sigma
 
    noisy_image = np.zeros(temp_image.shape, np.float64)
    if len(temp_image.shape) == 2:
        noisy_image = temp_image + noise
    else:
        noisy_image[:,:,0] = temp_image[:,:,0] + noise
        noisy_image[:,:,1] = temp_image[:,:,1] + noise
        noisy_image[:,:,2] = temp_image[:,:,2] + noise
        
    return noisy_image

#Add salt and pepper noise to an image
def add_sp_noise(pic,SNR=0.9,p=0.3):
    num = np.random.rand()
    if num >= p:
        return pic
    noisy_image = pic.copy()
    h, w, c = noisy_image.shape
    mask = np.random.choice((0, 1, 2), size=(1, h, w), p=[SNR, (1 - SNR) / 2., (1 - SNR) / 2.])
    mask = np.repeat(mask, c, axis=0)     # copy the mask by channel
    mask = np.transpose(mask,(1,2,0))
    noisy_image[mask == 1] = 255    # Salt
    noisy_image[mask == 2] = 0      # Pepper
    return noisy_image


@TestFactory.register('general_lungseg')
class GeneralLungseg(object):
    params = {
        'attack_types':{
            "description":"选择扰动的类型,从value_range中选择任意个数的扰动类型输入",
            "value_type":"list",
            "value_range":['defocus_blur','motion_blur','rgb_shift','rgb_shift','hsv_shift',"brightness_shift","iso_noise","sp_noise"],
            "default": ['defocus_blur','iso_noise']
        },
        'attack_levels':{
            "description":"每个扰动的等级，需要与上述扰动一一对应",
            "value_type":"list",
            "value_range":"1-5之间的整数",
            "default":[2,3]
        },
    }
    def __init__(self, attack_types=['defocus_blur','iso_noise'], attack_levels=[2,3]):
        super(GeneralLungseg, self).__init__()
        self.attack_types = attack_types
        self.attack_levels = attack_levels
        
    def run(self, img, label, meta, model, device):
        attack_dict = {}
        attack_list = []
        assert(len(self.attack_types)==len(self.attack_levels))
        for i,type in enumerate(self.attack_types):
            attack_dict[type] = self.attack_levels[i]
        if 'defocus_blur' in self.attack_types:
            level_list = [1,3,5,7,9]
            level = attack_dict['defocus_blur']
            blur_limit = level_list[int(level)-1]
            attack_list.append(albumentations.GaussianBlur(blur_limit=blur_limit, p=1))
        if 'motion_blur' in self.attack_types:
            level_list = [10,30,50,70,90]
            level = attack_dict['motion_blur']
            blur_limit = level_list[int(level)-1]
            attack_list.append(albumentations.MotionBlur(blur_limit=blur_limit,p=1))
        if 'rgb_shift' in self.attack_types:
            attack_list.append(albumentations.RGBShift(p=1))
        if 'hsv_shift' in self.attack_types:
            level_list = [5,10,15,20,25]
            level = attack_dict['hsv_shift']
            shift_limit = level_list[int(level)-1]
            attack_list.append(albumentations.HueSaturationValue(hue_shift_limit=shift_limit, sat_shift_limit=shift_limit, val_shift_limit=shift_limit, p=1))
        if 'brightness_contrast' in self.attack_types:
            level_list = [0.1,0.2,0.3,0.4,0.5]
            level = attack_dict['brightness_contrast']
            limit = level_list[int(level)-1]
            attack_list.append(albumentations.RandomBrightnessContrast(brightness_limit=limit, contrast_limit=limit, p=1))
        album = albumentations.Compose(attack_list)

        adv_img = album(image=img)["image"]
        if 'iso_noise' in self.attack_types:
            mean_list = [2,5,10,15,20]
            sigma_list = [30,40,50,60,70]
            level = attack_dict['iso_noise']
            idx = int(level) - 1
            adv_img = add_gaussian_noise(adv_img,[mean_list[idx],sigma_list[idx]],p=1)
        if 'sp_noise' in self.attack_types:
            level_list = [0.9,0.8,0.7,0.6,0.5]
            level = attack_dict['sp_noise']
            snr = level_list[int(level)-1]
            adv_img = add_sp_noise(adv_img,SNR=snr,p=1)
        # adv_img = cv2.cvtColor(adv_img.astype(np.uint8), cv2.COLOR_BGR2RGB)
        # adv_img = transform(adv_img.astype(np.uint8))
        new_meta = meta.copy()
        img = img_to_tensor(img)
        # print("Algorithm Device:",device)
        img = img.unsqueeze(0).to(device)
        y = torch.tensor([label]).to(device)
        with torch.no_grad():
            preds_ori = model.predict(img)
        adv_tensor = img_to_tensor(adv_img)
        adv_tensor = adv_tensor.unsqueeze(0).to(device)
        with torch.no_grad():
            preds_new = model.predict(adv_tensor)
        new_meta['pred_ori'] = preds_ori
        new_meta['pred_new'] = preds_new
        new_meta['label'] = label
        return adv_img, label, new_meta
```

**添加完成新的类后，需要在backend/lib/algorithms/\_\_init\_\_.py中将对应的文件import进来，以完成注册。**



##### step4 注册数据集评价类

在框架/backend/lib/newdata_eval/文件夹下存放新数据集评价的脚本，如eval_lungseg.py，完成其single与summary方法，single方法主要用于输出单张新图片的评价指标，summary方法则是生成关于整个数据集的评价指标，如平均准确率、平均ssim等。

```python
import os
import json
from typing import Callable
from pathlib import Path

import numpy as np
import skimage.io
from skimage.metrics import structural_similarity as ssim_score
# from obs import ObsClient

from .factory import NewdataEvalFactory

@NewdataEvalFactory.register('eval_lungseg')
class Lungseg_Basic(object):
    def __init__(self, *args, **kargs):
        super(Lungseg_Basic, self).__init__()
        self.args = args
        self.kargs = kargs


    def single(self, input_ori, label_ori, meta_ori, input_new, label_new, meta_new):
        input_ori = ssim_score(input_ori,input_new,*self.args,**self.kargs,multichannel=True) 

        score = {
            'ssim': input_ori,
        }

        return score


    def summary(cls, score_list):
        ssim_list = [score['ssim'] for score in score_list]
        preds_ori = np.array([score.pop('pred_ori') for score in score_list])
        preds_new = np.array([score.pop('pred_new') for score in score_list])
        masks = np.array([score.pop('label') for score in score_list])

        correct_ori = preds_ori[preds_ori == masks]
        correct_new = preds_new[preds_new == masks]
        correct_num_orig = correct_ori.sum()
        correct_num_new = correct_new.sum()
        correct2wrong_num = correct_num_orig - correct_num_new
        attack_rate = correct2wrong_num / correct_num_orig
        accuracy_ori = correct_ori.sum() / len(masks.flatten())
        accuracy_new = correct_new.sum() / len(masks.flatten())
        accuracy_loss = (accuracy_ori - accuracy_new) / accuracy_ori
        score = {
            'ssim': np.array(ssim_list).mean(),
            'attack_rate': attack_rate,
            'acc_ori': accuracy_ori,
            'acc_new': accuracy_new,
            'acc_loss': accuracy_loss
        }
        return score

```

**添加完成新的类后，需要在backend/lib/newdata_eval/\_\_init\_\_.py中将对应的文件import进来，以完成注册。**



##### step 5 编写yaml文件，指定模型参数

一个算法由很多参数控制，为了方便，统一将参数的设置存放在框架configs/文件夹中，如lungseg_create.yaml，create部分的参数主要包括上述四个部分的设置参数，示例如下：

```yaml
model:
  name: model_lungseg_basic
  params: 
    path: models/jit_lungseg.pth
    device: cuda
    threshold: 0.5

dataset:
  name: dataset_lungseg_basic
  params:
    root_dir: datasets/lung_seg
    resize: 864

newdata_evals:
  -
    newdata_eval_name: eval_lungseg
    newdata_eval_params: {}

algorithm:
  tests: 
  -
    name: general_lungseg
    params: 
      attack_types: ['gaussian_blur']
      attack_levels: ['2']
```



至此，新算法成功添加到框架中，可以运行backend/lib/core.py来验证，运行示例如下:

```shell
python backend/lib/core.py --create_path configs/lungseg_create.yaml --evaluate_path configs/lungseg_evaluate.yaml
```
有的时候，要改一下显卡
```shell
CUDA_VISIBLE_DEVICES=2 python backend/lib/core.py --create_path configs/lungseg_create.yaml --evaluate_path configs/lungseg_evaluate.yaml
```



